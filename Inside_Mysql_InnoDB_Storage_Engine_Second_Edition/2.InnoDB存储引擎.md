# 第2章 InnoDB存储引擎

## 2.3InnoDB体系架构
### 2.3.2内存

#### 1.缓冲池

#### 2.LRU List、Free List、Flush List

* Innidb中的缓冲池可以看做很大的内存区域，通过LRU来管理
* LRU（最近最少使用）也就是最频繁使用的页在LRU列表的最前端
* Innodb缓冲池中的页大小为16K
* Innodb存储引擎对LRU算法进行了优化
  * 添加了midpoint（mid）位置：新读取的页不会插入到队列头，而是插到这个点。也就是innodb_old_blocks_pct这个变量。
  *  还有innodb_old_blocks_time这个参数用于表示读取到mid后需要等待多久才会被加入到LRU的热端。
* LRU用来管理已经读取的页。而db刚启动的时候，LRU为空，此时页都存放在Free列表中。
* 在LRU列表中也被修改过后，就称作为脏页，也就是缓冲池中的页和磁盘上的页的数据产生了不一致，此时db会通过CHECKPOINT机制将脏页刷新回磁盘，而Flush list中的页就是脏页。
* LRU管理缓冲池中可用的页，Flush用来管理将要刷新的页，二者互不影响。

#### 3.重做日志缓冲

* redo log buffer
* Innodb存储引擎将重做日志信息先放到这个缓冲区，然后按一定的频率刷新到重做日志文件

#### 4.额外的内存池

* Innodb存储引擎对内存的管理通过内存堆（heap）的方式进行。
* 对一些数据结构本身的内存分配，需要额外的内存池中进行。

### 2.4Checkpoint技术

* 应为数据库的缓冲池和重做日志不能无限增大，并且在出现异常，数据库需哟恢复数据的时候，如果完全恢复日志（很大）的话时间很长，所以需要在一定情况下将数据库的脏页强制刷到磁盘上。这个技术就是Checkpoint技术。
* Checkpoint技术解决的问题：
  * 缩短数据库恢复时间
  * 缓冲池不够时，将脏页刷到磁盘
  * 重做日志不可用时，刷脏页到磁盘
* 上边说到的重做日志不可用：用为数据库一般是循环使用重做日志的空间，重做日志不会无限增大，已经刷脏到磁盘的空间可以覆盖使用，但是如果可以覆盖的空间还是不够，就需要强制刷脏页。
* 两种Checkpoint
  * Sharp Checkpoint：发生在数据库关闭时
  * Fuzzy Checkpoint：发生在运行时

### 2.5Master Thread工作方式

#### 2.5.1 InnoDB1.0.x版本前的Master Thread

* Master Thread具有最高优先级的线程
* Master Thread会根据数据库运行状态在Loop ，background loop ，flush loop，suspend（暂停）loop中切换
* Loop为主循环，大多数操作都在其中，有两大部分操作：每秒钟和每10秒的操作：
  * 每秒的操作：
    * 日志缓冲刷新到磁盘，即使这个事务没有提交（将重做日志缓冲中的内容刷新到重做日志，这一点就是解释了为什么再大的事务commit夜很快）
    * 合并插入缓冲
    * 至多刷新100个innoDB的缓冲池中的脏页（可能）
    * 如果当前用户没有操作，切换到background loop
  * 每10秒进行的操作
    * 刷新100个脏页到磁盘（可能的话）
    * 合并至多5个插入缓冲（总是）
    * 将日志缓冲刷新到磁盘（总是）
    * 删除无用的undo页（总是）
    * 刷新100个或者10个脏页到磁盘（总是）
* background loop（后台循环）
  * 如果当前没有用户活动（数据库空闲）或者数据库关闭（shutdown）就会切换到这个循环
  * 会进行的操作：
    * 删除无用的Undo页（总是）
    * 合并20个插入缓冲（总是）
    * 跳回主循环（总是）
    * 不断刷新100个页直到符合条件（可能，跳转到flush loop）
  * 如何flush loop中没有操作，就会跳到 suspend loop（暂停），讲Master Thread挂起

#### 2.5.2  InnoDB1.1.x版本前的Master Thread

* 上个版本的实现，包含很多的硬编码，比如美妙具体的限制刷新的个数或大小
* 主要修改了刷新脏页操作和合并插入缓冲的操作，还有回收Undo页的机制

#### 2.5.3  InnoDB1.3.x版本前的Master Thread

* 讲刷新脏页的线程独立出Master Thread，变成Page Cleaner Thread
### 2.6 Innodb的关键特性

#### 2.6.1 插入缓冲（insert buffer）

* insert buffer和数据页一样是，也是物理页的一个组成部分
* 因为非聚集索引插入性能差（B+树的特点决定），所以设计了insert buffer
  * 对于非聚集索引的插入，并不是每次都直接插入非聚集索引页，而是先判断插入的非聚集索引页是否在缓冲池中，若在直接插入，若不在则先放到insert buffer对象中，再按一定的频率和数量进行insert buffer和非索引叶子节点的merge，这时通常是讲多个插入合并到一个操作中（因为在一个索引页中），提升了性能
  * insert buffer使用的要求：辅助索引，索引不唯一（辅助索引不能是唯一的，因为在插入缓冲时，数据库不会去查找索引页来判断插入的记录的唯一性，如果去查找又产生了离散读的情况，insert buffer失去意义）
* 但是如果，在大量写的操作中db宕机，大量的插入在insert buffer中没有合并到实际的索引中去，所以恢复耗时，这个insert buffer一般占innode_buffer_pool的一般，percona有patch来调小这个值，提升恢复性能
* innodb的1.0.x版本加入了change buffer，可以说是insert buffer的升级版本，讲DDL（insert、delete、update都进行缓冲），还时适用于非唯一的辅助索引。

#### 2.6.2 两次写

* 提升了innodb引擎数页的可靠性
* 场景：写入数据时只写入了一部分数据，db宕机，这就是部分失效，通过doublewrite来解决。
* 重做日志中记录的时多页的物理操作，如偏移量800，写'aaa'，但是如果这个页本身发生损坏，再进行重做没有意义。这就是说在应用（apply）重做日志前，用户需要一个页的副本，当写入失效发生时，先通过副本来还原页，再进行重做。这就是doublewrite。
* doublewrite的组成是：内存中的doublewrite buffer为2MB，另外为物理磁盘上的128个页，就是2个区（extent），也为2MB。
* 在对缓冲池的脏页刷新时，并不直接写磁盘，先memcpy将脏页复制到内存中的doublewrite，之后通过doublewrite buffer分两次，每次1M的顺序写到共享表空间的物理磁盘上，同时调用fsync函数，同步刷盘，避免缓冲写带来的问题。这个过程中doublewrite页时连续的，所以这个过程顺序写，开销不大。完成doublewrite页的写后，再将doublewrite buffer中的页写入各个表空间文件中，此时写入时离散的。